{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Eric\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding to float32\n"
     ]
    }
   ],
   "source": [
    "# We adopt the idea proposed in the following link and get the score of 0.0652554.\n",
    "# https://www.kaggle.com/anokas/simple-xgboost-starter-0-0655\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "# This is for the successful importing of xgboost\n",
    "import os\n",
    "mingw_path = 'D:\\\\Program Files\\\\mingw-w64\\\\x86_64-7.1.0-posix-seh-rt_v5-rev2\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + \";\" + os.environ['PATH']\n",
    "import xgboost as xgb\n",
    "\n",
    "print('Loading data ...')\n",
    "\n",
    "train = pd.read_csv('input/train_2016_v2.csv')\n",
    "prop = pd.read_csv('input/properties_2016.csv')\n",
    "sample = pd.read_csv('input/sample_submission.csv')\n",
    "\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\n",
    "\tif dtype == np.float64:\n",
    "\t\tprop[c] = prop[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training set ...\n",
      "(90275, 55) (90275,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Creating training set ...')\n",
    "\n",
    "df_train = train.merge(prop, how='left', on='parcelid')\n",
    "\n",
    "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode'], axis=1)\n",
    "y_train = df_train['logerror'].values\n",
    "\n",
    "train_columns = x_train.columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n",
    "    \n",
    "del df_train; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building DMatrix...\n",
      "Training ...\n",
      "[0]\ttrain-mae:0.488065\tvalid-mae:0.48112\n",
      "Multiple eval metrics have been passed: 'valid-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mae hasn't improved in 100 rounds.\n",
      "[10]\ttrain-mae:0.402221\tvalid-mae:0.395444\n",
      "[20]\ttrain-mae:0.33268\tvalid-mae:0.326098\n",
      "[30]\ttrain-mae:0.276518\tvalid-mae:0.270132\n",
      "[40]\ttrain-mae:0.231316\tvalid-mae:0.225213\n",
      "[50]\ttrain-mae:0.195059\tvalid-mae:0.189317\n",
      "[60]\ttrain-mae:0.166121\tvalid-mae:0.16072\n",
      "[70]\ttrain-mae:0.143115\tvalid-mae:0.138042\n",
      "[80]\ttrain-mae:0.124973\tvalid-mae:0.120213\n",
      "[90]\ttrain-mae:0.11079\tvalid-mae:0.106351\n",
      "[100]\ttrain-mae:0.099822\tvalid-mae:0.095702\n",
      "[110]\ttrain-mae:0.091454\tvalid-mae:0.087592\n",
      "[120]\ttrain-mae:0.085149\tvalid-mae:0.08158\n",
      "[130]\ttrain-mae:0.080456\tvalid-mae:0.077192\n",
      "[140]\ttrain-mae:0.077015\tvalid-mae:0.074063\n",
      "[150]\ttrain-mae:0.07451\tvalid-mae:0.071827\n",
      "[160]\ttrain-mae:0.072688\tvalid-mae:0.070245\n",
      "[170]\ttrain-mae:0.071374\tvalid-mae:0.069129\n",
      "[180]\ttrain-mae:0.070415\tvalid-mae:0.068366\n",
      "[190]\ttrain-mae:0.069715\tvalid-mae:0.067854\n",
      "[200]\ttrain-mae:0.069209\tvalid-mae:0.067512\n",
      "[210]\ttrain-mae:0.068828\tvalid-mae:0.06727\n",
      "[220]\ttrain-mae:0.068547\tvalid-mae:0.067113\n",
      "[230]\ttrain-mae:0.068334\tvalid-mae:0.067006\n",
      "[240]\ttrain-mae:0.068171\tvalid-mae:0.066937\n",
      "[250]\ttrain-mae:0.068039\tvalid-mae:0.066892\n",
      "[260]\ttrain-mae:0.067937\tvalid-mae:0.066866\n",
      "[270]\ttrain-mae:0.067856\tvalid-mae:0.066848\n",
      "[280]\ttrain-mae:0.067789\tvalid-mae:0.06684\n",
      "[290]\ttrain-mae:0.067735\tvalid-mae:0.066836\n",
      "[300]\ttrain-mae:0.067691\tvalid-mae:0.066838\n",
      "[310]\ttrain-mae:0.067655\tvalid-mae:0.066842\n",
      "[320]\ttrain-mae:0.067618\tvalid-mae:0.066841\n",
      "[330]\ttrain-mae:0.067586\tvalid-mae:0.066845\n",
      "[340]\ttrain-mae:0.067563\tvalid-mae:0.06686\n",
      "[350]\ttrain-mae:0.06754\tvalid-mae:0.066865\n",
      "[360]\ttrain-mae:0.067518\tvalid-mae:0.066872\n",
      "[370]\ttrain-mae:0.0675\tvalid-mae:0.066875\n",
      "[380]\ttrain-mae:0.067482\tvalid-mae:0.066877\n",
      "Stopping. Best iteration:\n",
      "[288]\ttrain-mae:0.067745\tvalid-mae:0.066835\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = 80000\n",
    "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "del x_train, x_valid; gc.collect()\n",
    "\n",
    "print('Training ...')\n",
    "\n",
    "params = {}\n",
    "params['eta'] = 0.02\n",
    "params['objective'] = 'reg:linear'\n",
    "params['eval_metric'] = 'mae'\n",
    "params['max_depth'] = 4\n",
    "params['silent'] = 1\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "clf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=10)\n",
    "\n",
    "del d_train, d_valid; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building test set ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Building test set ...')\n",
    "\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "del prop; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Eric\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = df_test[train_columns]\n",
    "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "    x_test[c] = (x_test[c] == True)\n",
    "\n",
    "del df_test, sample; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2985217\n",
      "(2985217,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ranges = np.linspace(0, x_test.shape[0], num=100, endpoint=True, dtype=int)\n",
    "p_test_list = []\n",
    "for i in range(len(test_ranges) - 1):\n",
    "    d_test = xgb.DMatrix(x_test[test_ranges[i] : test_ranges[i+1]])\n",
    "    p_test = clf.predict(d_test)\n",
    "    p_test_list.append(np.array(p_test))\n",
    "\n",
    "p_test = np.hstack(p_test_list)\n",
    "\n",
    "del x_test; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217,) (2985217,)\n",
      "(2985217,) (2985217,)\n",
      "(2985217,) (2985217,)\n",
      "(2985217,) (2985217,)\n",
      "(2985217,) (2985217,)\n",
      "(2985217,) (2985217,)\n",
      "Writing csv ...\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('input/sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    print(sub[c].shape, p_test.shape)\n",
    "    sub[c] = p_test\n",
    "    \n",
    "print('Writing csv ...')\n",
    "sub.to_csv('xgb_starter.csv', index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
